{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "517777e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ce68330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_semantic_similarity(sentences, model):\n",
    "    #Compute embeddings\n",
    "    embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "    \n",
    "    #Compute cosine-similarities for each sentence with each other sentence\n",
    "    cosine_scores = util.cos_sim(embeddings, embeddings)\n",
    "    # Extract upper/lower half\n",
    "    upper_half = torch.triu(cosine_scores, diagonal=1)\n",
    "    upper_half = upper_half[upper_half != 0]\n",
    "#     upper_half = upper_half[upper_half != 1.0]\n",
    "    average = torch.mean(upper_half)\n",
    "    return average.item(), cosine_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99d40549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "def read_eval_results(results):\n",
    "    with open(results, 'r') as json_file:\n",
    "        json_list_str = list(json_file)\n",
    "    json_data = dict()\n",
    "    json_list = list()\n",
    "    for json_str in json_list_str:\n",
    "        result = json.loads(json_str)\n",
    "        json_data[str(uuid.uuid4())] = result\n",
    "        json_list.append(result)\n",
    "    return json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbadf1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_generations_from_json_data(json_list):\n",
    "    all_generations = []\n",
    "    for item in data:\n",
    "        try:\n",
    "            all_generations.append(item['generation'][0])\n",
    "        except:\n",
    "            print(item['generation'])\n",
    "            all_generations.append([])\n",
    "    return all_generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "066d8120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_generations = []\n",
    "# import pickle\n",
    "# with open(\"/Users/sankethrangreji/Coursework/11797 Question Answering/QA11797/LLaMA-2 70b results/llama_text_gsmhard_processed_generations.pkl\", \"rb\") as f:\n",
    "#     all_generations = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fee49b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def read_pickle_generations(filepath):\n",
    "    all_generations = []\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        all_generations = pickle.load(f)\n",
    "    return all_generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b99f6c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_eval_results(\"/Users/sankethrangreji/Coursework/11797 Question Answering/QA11797/openai code generations/gsm_code_text-davinci-003_t_1_k_10.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "45e7555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3531f998",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_generations = []\n",
    "for item in data:\n",
    "    try:\n",
    "        all_generations.append(item['generation'][0])\n",
    "    except:\n",
    "        print(item['generation'])\n",
    "        all_generations.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d609e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_generations = read_pickle_generations(\"/Users/sankethrangreji/Coursework/11797 Question Answering/QA11797/temperature_experiments/1_0/Code Generations/vllm_llama2_70b_1_object_counting_code_generation.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "253efb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8c30e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_generations[34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1298c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbf836d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_similarity_score_all_generations(model, all_generations):\n",
    "    avg_similarity_scores = []\n",
    "    for generations in tqdm(all_generations):\n",
    "        if generations:\n",
    "            avg, cosine_scores = get_average_semantic_similarity(generations, model)\n",
    "            avg_similarity_scores.append(avg)\n",
    "    return np.mean(avg_similarity_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e883da",
   "metadata": {},
   "source": [
    "### Uncomment and run below cell for obtainining similarity score for a single file read above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b9f3884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_similarity_scores = []\n",
    "# for generations in tqdm(all_generations):\n",
    "#     if generations:\n",
    "#         avg, cosine_scores = get_average_semantic_similarity(generations, model)\n",
    "#         avg_similarity_scores.append(avg)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ef16fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(avg_similarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a392d40a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bcc8f5",
   "metadata": {},
   "source": [
    "### Run below cells to generate similarity scores for all result or pickle files in the given folder(to be provided as FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48096f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21e9b162",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"/Users/sankethrangreji/Coursework/11797 Question Answering/QA11797/temperature_experiments_13b/0_7/Text generations/*.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2e52b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:03<00:00,  9.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for /Users/sankethrangreji/Coursework/11797 Question Answering/QA11797/temperature_experiments_13b/0_7/Text generations/vllm_llama2_13b_0.7_repeat_copy_text_generation.pkl is : 0.9507282245904207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 1319/1319 [03:23<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for /Users/sankethrangreji/Coursework/11797 Question Answering/QA11797/temperature_experiments_13b/0_7/Text generations/vllm_llama2_13b_0.7_gsmhardv2_text_generation.pkl is : 0.8348019924283118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 369/369 [00:27<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for /Users/sankethrangreji/Coursework/11797 Question Answering/QA11797/temperature_experiments_13b/0_7/Text generations/vllm_llama2_13b_0.7_date_understanding_text_generation.pkl is : 0.8681171933809916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 1319/1319 [02:40<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for /Users/sankethrangreji/Coursework/11797 Question Answering/QA11797/temperature_experiments_13b/0_7/Text generations/vllm_llama2_13b_0.7_gsm_text_generation.pkl is : 0.8540954859849628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 250/250 [00:14<00:00, 16.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for /Users/sankethrangreji/Coursework/11797 Question Answering/QA11797/temperature_experiments_13b/0_7/Text generations/vllm_llama2_13b_0.7_object_counting_text_generation.pkl is : 0.9865523309707641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "pattern = FILE_PATH\n",
    "\n",
    "# Use glob to get a list of files that match the pattern\n",
    "file_list = glob.glob(pattern)\n",
    "\n",
    "# Now, file_list contains the paths of all .pkl files in the current directory\n",
    "# You can loop through this list to process these files or perform any other operations.\n",
    "for file_path in file_list:\n",
    "    all_generations = []\n",
    "    try:\n",
    "        if file_path.endswith('pkl'):\n",
    "            all_generations = read_pickle_generations(file_path)\n",
    "#             print(all_generations[0])\n",
    "        elif file_path.endswith('jsonl'):\n",
    "            data = read_eval_results(file_path)\n",
    "            all_generations = get_all_generations_from_json_data(data)\n",
    "#             print(all_generations[0])\n",
    "        else:\n",
    "            print(\"Invalid file type {}\".format(file_path.split(\"/\")[-1].split(\".\")[-1]))\n",
    "            continue\n",
    "        if all_generations:\n",
    "            score = get_avg_similarity_score_all_generations(model, all_generations)\n",
    "        print(\"Score for {} is : {}\".format(file_path.split('\\n')[-1], score))\n",
    "    except Exception as e:\n",
    "        print(\"Error : \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480efea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
